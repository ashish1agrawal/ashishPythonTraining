---
title: "Analysis of the Company Financial Manipulations"
author: "Kumar Rahul"
date: "20 September 2016"
output: word_document
---

The analysis is on company financial manipulations and devise algorithm to identify a manipulater from a non manipulater based on the financial ratios reported by the companies. There are a total of 1239 observations in the data set. Out of these 1239 observations, there are 1200 non manipulaters and 39 manipulaters.

> 1. [Look](http://topepo.github.io/caret/train-models-by-tag.html) for different types of model which can be built using R. Also has a guideline for fine tuning paramters
> 2. Refer [link](http://stats.stackexchange.com/questions/163799/training-a-random-forest-in-r-with-a-maximum-false-positive-rate) to know random forest and [Refer](http://stackoverflow.com/questions/18541923/what-is-out-of-bag-error-in-random-forests) to know about OOB error
> 3. [Demonstration](https://rpubs.com/chengjiun/52658) of some of the bagging and boosting algorithm
> 4. [Understand](https://www.r-bloggers.com/improve-predictive-performance-in-r-with-bagging/) the logic for bagging in logistic regression
> 5. [Interpret](http://stackoverflow.com/questions/14996619/random-forest-output-interpretation) the tree structure generated out of random forest model

***

```{r, include=FALSE}
library(caret)            #for split and model accuracy
library(DMwR)             #for SMOTE Sampling
library(randomForest)
library(ROCR)             #for ROC Plot
library(fastAdaboost)     #to use the get_tree()
library(rattle)           #print the business rules for the model
library(inTrees)          #to extract the business rules from rf model
library(UBL)
setwd("/Users/Rahul/Documents/Rahul Office/IIMB/Work @ IIMB/Company Fraud")
```

## Preparing data

####Read data from a specified location
```{r, echo=TRUE}
raw.data <- read.csv("/Users/Rahul/Documents/Rahul Office/IIMB/Work @ IIMB/Company Fraud/fraud_data.csv",head=TRUE,na.strings=c("", " ", "NA"), sep=",")

filter.data <- raw.data[,-c(1)]
```

####Define an 70%/30% train/test split of the dataset
```{r}
set.seed(4121)
trainIndex <- createDataPartition(filter.data$Manipulater, p = 0.70, list=FALSE)
data.train <- filter.data[ trainIndex,]
data.test <- filter.data[-trainIndex,]
```

####Prepare and run numerical summaries
```{r}
summary(data.train) #summary of the data
data.train <- na.omit(data.train) # listwise deletion of missing
data.test <- na.omit(data.test) # listwise deletion of missing
```

####Train and test dataset with needed variables
```{r}
model.data <- as.data.frame(filter.data[,c(#"DSRI",
                                       #"GMI",
                                       "AQI",
                                       #"SGI",
                                       "DEPI",
                                       "SGAI",
                                       "ACCR",
                                       "LEVI",
                                       "Manipulater"
)])

model.train <- as.data.frame(data.train[,c(#"DSRI",
                                          #"GMI",
                                          "AQI",
                                          #"SGI",
                                          "DEPI",
                                          "SGAI",
                                          "ACCR",
                                          "LEVI",
                                          "Manipulater"
)])

model.test <- as.data.frame(data.test[,c(#"DSRI",
                                        #"GMI",
                                        "AQI",
                                        #"SGI",
                                        "DEPI",
                                        "SGAI",
                                        "ACCR",
                                        "LEVI",
                                        "Manipulater"
)])

```

####Corelation amongst variable

The below chunk of code will show the co-relation if any between the numerical variables. The function **highlyCorelated()** shows the variables which are corelated with an absolute corelation of more than 0.6. In this case there are no variables which are highly corelated.
```{r corMatrix, echo=TRUE, tidy=TRUE, warning=FALSE}
correlationMatrix <- cor(model.data[,c(1:5)])
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.7)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff = 0.6, names = TRUE)
print(highlyCorrelated)
```

##Caret Package

**caret** is a useful and a robust package which helps to set a generic framework to implement any kind of model in R. Some of the algorithm's which can be implemented using caret package are:
```{r, echo=TRUE}
names(getModelInfo())

#getModelInfo()$glm
```


## Bagging Model

Bagging is the process of taking bootstrap sample and then aggreagting the model learned on each sample. Each of the models are trained independently on the N observations picked randomly from N observations in the original dataset (with replacement). The models can be trained parallely as the training is based on independent samples. Since models are trained on different but overlapping samples of the original data, the predictions from different models will be different.

### Bagging models in R

The  algorithms in bagging are:

> 1. Bagged Adaboost: **_adabag()_** Required Package is **adabag, plyr**
2. Bagged CART: **_treebag()_** Required Package is **ipred, e1071, plyr**
3. Bagged Flexible Discriminant Analysis: **_bagFDA()_** Required Package is **earth, mda**
4. Bagged Logic Regression: **_logicBag()_** Required Package is **logicFS**
5. Bagged MARS: **_bagEarth()_** Required Package is **earth**
6. Bagged Model: **_bag()_** Required Package is **caret**
7. Ensemble of Generalized Linear Models: **_randomGLM()_** Required Package is **randomGLM**
8. Model Averaged Neural Network: **_avNNET()_** Required Package is **nnet**
9. Quantile Regression Neural Network: **_qrnn()_** Required Package is **qrnn**
10. Random Ferns: **_rFerns()_** Required Package is **rFerns**

_The below methods are all applicable to implement random forest as a bagging algorithm:_

> 11. Parallel Random Forest: **_parRF()_** Required Package is **e1071, randomForest, foreach**
12. Quantile Random Forest: **_qrf()_** Required Package is **quantregForest**
13. Conditional Inference Random Forest: **_cforest()_** Required Package is **party**
14. Random Forest: **_ranger()_** Required Package is **e1071, ranger**
15. Random Forest: **_Rborist()_** Required Package is **Rborist**
16. Random Forest: **_rf()_** Required Package is **randomForest**
17. Random Forest by Randomization: **_extraTrees()_** Required Package is **extraTrees**
18. Random Forest rule based Model: **_rfRules()_** Required Package is **randomForest, inTrees, plyr**
19. Regularized Random Forest: **_RRF()_** Required Package is **randomForest, RRF**
20. Regularized Random Forest: **_RRFglobal()_** Required Package is **RRF**
21. Weighted Subspace Random Forest: **_wsrf()_** Required Package is **wsrf**


###Random Forest with bootstrap sampling
Random forests is one of the algorithm which uses bagging as a technique. In the below code chunk we will use bootstrap sampling to implement bagging using rf method. This means that if there are 100 observations in a training dataset the resulting sample will select 100 samples with replacement.

The below code chunk sets some of the control parameters
```{r, echo=TRUE, warning=FALSE}
objControl <- trainControl(method='boot', number = 1,
                           returnResamp='none', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE)
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

rf.bootstrap.model <- train(model.train[,1:5], model.train[,6], 
                  method='rf', 
                  trControl=objControl, ntree = 500,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for bootstrap sampling on train set
```{r, echo=TRUE}
#rf.bootstrap.model$finalModel #rf.bootstrap.model$results
print(rf.bootstrap.model)
confusionMatrix.train(rf.bootstrap.model)
plot(varImp(rf.bootstrap.model), main = "Variable importance from Bootstrap Random Forest", col = 2, lwd = 2)
```

Confusion Matrix for bootstrap sampling on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(rf.bootstrap.model, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for bootstrap random forest on test set
```{r, echo=TRUE}
rf.bootstrap.pred <- predict(rf.bootstrap.model, model.test, type = "prob")[,2]
rf.bootstrap.prediction <- prediction(rf.bootstrap.pred,model.test$Manipulater)
rf.bootstrap.perf <- performance(rf.bootstrap.prediction, "tpr","fpr")

plot(rf.bootstrap.perf,main="ROC Curve for bootstrap Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(rf.bootstrap.prediction, "auc")
```

The best model was
```{r, echo=TRUE}
rf.bootstrap.model$bestTune
```

Visulaizing the rules coming out of random forest. We can loop and print all the trees built using up sampling. For simplicity, printing just one of the trees

```{r, eval=FALSE, include=FALSE}
getTree(rf.bootstrap.model$finalModel,3)
```

###Random Forest with up sampling
To incorporate up-sampling (sample the minority class to make their frequencies closer to the majority class.), random forest can use an upsampling strategy

The below code chunk sets some of the control parameters
```{r, echo=TRUE, warning=FALSE}
objControl <- trainControl(method='boot', number = 1,
                           returnResamp='final', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE,
                           sampling="up")
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

rf.up.model <- train(model.train[,1:5], model.train[,6], 
                  method='rf', 
                  trControl=objControl,  
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for upsampling on train set
```{r, echo=TRUE}
#rf.up.model$finalModel #rf.up.model$results 

print(rf.up.model)
confusionMatrix.train(rf.up.model)
plot(varImp(rf.up.model), main = "Variable importance from Bootstrap Random Forest", col = 2, lwd = 2)
```

Confusion Matrix for upsampling on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(rf.up.model, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for upsample random forest on test set
```{r, echo=TRUE}
rf.up.pred <- predict(rf.up.model, model.test, type = "prob")[,2]
rf.up.prediction <- prediction(rf.up.pred,model.test$Manipulater)
rf.up.perf <- performance(rf.up.prediction, "tpr","fpr")

plot(rf.up.perf,main="ROC Curve for Up Sample Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(rf.up.prediction, "auc")
```

Extracting all the rules from the trees built using random forest
```{r, eval=FALSE, include=FALSE}
rf.up.treelist <- RF2List(rf.up.model$finalModel)
rf.up.rules <- extractRules(rf.up.treelist,model.train[,c(1:5)], ntree = 500)
rf.up.rules.metric <- getRuleMetric(rf.up.rules,model.train[,c(1:5)],model.train[,6])
rf.up.rules.metric <- pruneRule(rf.up.rules.metric,model.train[,c(1:5)],model.train[,6])
rf.up.rules.metric <- selectRuleRRF(rf.up.rules.metric,model.train[,c(1:5)],model.train[,6])

#readable rules
print(presentRules(rf.up.rules.metric, colnames(model.train[,c(1:5)])))
#rf.up.learner <- buildLearner(rf.up.rules.metric,model.data[,c(1:6)],model.data[,7])
```


###Random Forest with down sampling - First Approach
To incorporate down-sampling (sample the majority class to make their frequencies closer to the minority class.), random forest can use an downsampling strategy

The below code chunk sets some of the control parameters
```{r, echo=TRUE, warning=FALSE}
objControl <- trainControl(method='boot', number = 1,
                           returnResamp='final', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE,
                           sampling="down")
```

After setting the control parameters, the model is run
```{r, echo=TRUE}
set.seed(4121)

rf.down1.model <- train(model.train[,1:5], model.train[,6], 
                  method='rf', 
                  trControl=objControl,  
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for down sampling RF on train set
```{r, echo=TRUE}
#rf.down1.model$finalModel #rf.down1.model$results 
print(rf.down1.model)
confusionMatrix.train(rf.down1.model)
plot(varImp(rf.down1.model), main = "Variable importance from down sample Random Forest", col = 2, lwd = 2)
```

Confusion Matrix for down sampling RF on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(rf.down1.model, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for down sample random forest on test set
```{r, echo=TRUE}
rf.down1.pred <- predict(rf.down1.model, model.test, type = "prob")[,2]
rf.down1.prediction <- prediction(rf.down1.pred,model.test$Manipulater)
rf.down1.perf <- performance(rf.down1.prediction, "tpr","fpr")

plot(rf.down1.perf,main="ROC Curve for Down Sample Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(rf.down1.prediction, "auc")
```

### Random Forest with down sampling - Second Approach
To incorporate down-sampling (sample the majority class to make their frequencies closer to the rarest class.), random forest can take a random sample of size c*nmin, where c is the number of classes and nmin is the number of samples in the minority class.

**_THIS IMPLEMENTATION IS WITHOUT CARET PACKAGE_**
```{r, echo=TRUE}
nmin <- sum(model.train$Manipulater == "Yes") #total minority cases
set.seed(4121)
rf.down2.model <- randomForest(Manipulater ~ .,
                         data=model.train, importance=TRUE, mtry = 2,
                         #if strata is not defined RF does bootstrap sample
                         strata = model.train$Manipulater,
                         #selecting nmin cases from positive and negative class
                         sampsize = rep(nmin,2),
                         #cutoff: ‘winning’ class for an observation is the one 
                         #with the maximum ratio of proportion of votes to cutoff.  
                         cutoff = c(1/2, 1/2),ntree=1024,  nodesize = 10,
                         keep.forest = TRUE)#, xtest = model.test[,-12])
```

Variable importance and Confusion matrix on downsample random forest on train set
```{r, echo=TRUE}
#To plot the error rate.
#plot(rf.down2.model, main = "Error rate vs. number of trees (RF with downsample", type = "l", lwd = 3)

#To know the legends, type rf.down2.model to get the confusion matrix and #see the error

print(rf.down2.model)

varImpPlot(rf.down2.model, main = "Variable Importance Plot with Down Sample", pch = 16, col = 'darkred')
```


Variable importance and Confusion matrix on downsample random forest on test set
```{r, echo=TRUE}
testPredictedClass <- predict(rf.down2.model, model.test, type = "response")
confusionMatrix(testPredictedClass,model.test$Manipulater)
```

ROC plot for Random Forest with downsampling on test set
```{r, echo=TRUE}
rf.down2.pred <- predict(rf.down2.model, model.test, type = "prob")[,2]
rf.down2.prediction <- prediction(rf.down2.pred,model.test$Manipulater)
rf.down2.perf <- performance(rf.down2.prediction, "tpr","fpr")

plot(rf.down2.perf,main="ROC Curve for RF with Down Sampling",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(rf.down2.prediction, "auc")
```

### Random Forest with SMOTE

Synthetic minority oversampling technique (SMOTE) blends under-sampling of the majority class with a special form of over-sampling the minority class. SMOTE oversamples the rare event by using bootstrapping and k-nearest neighbor to synthetically create additional observations of that event.

The below code chunk sets some of the control parameters
```{r, echo=TRUE, warning=FALSE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='final', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE,
                           sampling="smote")
```

After setting the control parameters, the model is run
```{r, echo=TRUE}
set.seed(4121)

rf.smote.model <- train(model.train[,1:5], model.train[,6], 
                  method='rf', 
                  trControl=objControl,  
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for RF on train set
```{r, echo=TRUE}
#rf.smote.model$finalModel #rf.smote.model$results 
print(rf.smote.model)
confusionMatrix.train(rf.smote.model)
plot(varImp(rf.smote.model), main = "Variable importance from SMOTE Random Forest", col = 2, lwd = 2)
```

Confusion Matrix for RF on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(rf.smote.model, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for random forest on test set
```{r, echo=TRUE}
rf.smote.pred <- predict(rf.smote.model, model.test, type = "prob")[,2]
rf.smote.prediction <- prediction(rf.smote.pred,model.test$Manipulater)
rf.smote.perf <- performance(rf.smote.prediction, "tpr","fpr")

plot(rf.smote.perf,main="ROC Curve for Random Forest with SMOTE",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(rf.smote.prediction, "auc")
```

## Boosting
Boosting is an ensemble technique which tries to create a strong classifier from several weak classifier. The model buidling through boosting is sequential. 
1. The first model is build based on the random sample on N observations picked from original dataset (with replacement). Equal weight is assigned to each observation. These weights decide the probability of observations which will be picked up in the training set.
2. In the second step, all the original dataset is passed through the model. For regressor model, the observations whose predicted value differs the most from the actual value is defined to be most in error. 
3. The sampling probabilities of the observations which are most in error, is adjusted such that their chance of getting picked up for the second model is higher.
4. As the model buidling progresses, in each of the sequence of models, the pattern which are more difficult are picked up. Different models are better in different part of the observation space.
5. Rgeressors are combined using weighted median. Models which are more confident about their predictions are weighted more heavily.

###Boosting algorithms in R
Adaboost is one of the ways to boost the performance of decision trees on binary classification problems. The decision trees with just one level will mostly be a weak learner. These weak learners will achieve an accuracy just above random chance on a classification problem.

Adaboost is also referred to as discrete AdaBoost as it is used for classification rather than regression. The algorithms in boosting are:

> 1. Adaboost classification trees: **_adaboost()_** Required Package is **fastAdaboost**
2. Adaboost.M1: **_AdaBoost.M1()_** Required Package is **adabag, plyr**
3. Boosted Classification Trees: **_ada()_** Required Package is **adabag, plyr**
4. Boosted Generalized Additive Model: **_gamBoost()_** Required Package is **mboost, plyr**
5. Boosted Generalized Linear Model: **_glmboost()_** Required Package is **mboost, plyr**
6. Boosted Linear Model: **_Bstlm()_** Required Package is **bst, plyr**
7. Boosted Logistic Regression: **_LogitBoost()_** Required Package is **caTools**
8. Boosted Smoothing Spline: **_bstSm()_** Required Package is **bst, plyr**
9. Boosted Tree: **_blackboost()_** Required Package is **party, mboost, plyr**
10. Boosted Tree: **_bstTree()_** Required Package is **bst, plyr**
11. C5.0: **_C5.0()_** Required Package is **C50, plyr**
12. Cost Sensitive C5.0: **_C5.0Cost()_** Required Package is **C50, plyr**
13. Cubist: **_glmboost()_** Required Package is **cubist**
14. DeepBoost: **_deepboost()_** Required Package is **deepboost**
15. eXtreme Gradient Boosting: **_xgbLinear()_** Required Package is **xgboost**
16. eXtreme Gradient Boosting: **_xgbTree()_** Required Package is **xgboost, plyr**
17. Stochastic Gradient Boosting: **_gbm()_** Required Package is **gbm, plyr**

###Boosting with adaboost (normal CV)
The below code chunk sets some of the control parameters for adaboost
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='all', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE)#, p = 0.70) #in case method = #"LGOCV"
```

```{r}
search.grid <- expand.grid(mfinal = (1:10)*10, maxdepth = c(1:4),
                    coeflearn = c("Breiman", "Freund", "Zhu"))
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

ada.model <- train(model.train[,1:5], model.train[,6], 
                  method='AdaBoost.M1', 
                  trControl=objControl,
                  tuneGrid = search.grid,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for adaboost on train set
```{r, echo=TRUE}
#ada.model$finalModel #ada.model$results
print(ada.model)
confusionMatrix.train(ada.model)
plot(varImp(ada.model), main = "Variable importance from Adaboost", col = 2, lwd = 2)
```

Confusion Matrix for adaboost on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(ada.model, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for adaboost on test set
```{r, echo=TRUE}
ada.pred <- predict(ada.model, model.test, type = "prob")[,2]
ada.prediction <- prediction(ada.pred,model.test$Manipulater)
ada.perf <- performance(ada.prediction, "tpr","fpr")

plot(ada.perf,main="ROC Curve for adaboost",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(ada.prediction, "auc")
```

Visulaizing the rules coming out of ada boost. We can loop and print all the trees which was built using boosting. For simplicity, we are printing just one of the trees

To retrieve the understand any model specific attribute, we have to call the **$finalmodel** of the train object created using caret package. This is a generic way to use functions which are model specific. Here **get_tree()** is a function of **fastadaboost** package which cannot be used unless the the object returned is not of adaboost class.

```{r, echo=TRUE}
#listTreesAda(ada.model$finalModel,3) #this is a function with rattle package
#get_tree(ada.model$finalModel,2)
```

###Boosting with adaboost (upsample)
The below code chunk sets some of the control parameters for adaboost
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='all', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE,
                           sampling = "up")#, p = 0.70) #in case method = #"LGOCV"
```

```{r}
search.grid <- expand.grid(mfinal = (1:10)*10, maxdepth = c(1,4),
                    coeflearn = c("Breiman", "Freund", "Zhu"))
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

ada.up.model <- train(model.train[,1:5], model.train[,6], 
                  method='AdaBoost.M1', 
                  trControl=objControl,
                  tuneGrid = search.grid,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for adaboost on train set
```{r, echo=TRUE}
#ada.up.model$finalModel #ada.up.model$results
print(ada.up.model)
confusionMatrix.train(ada.up.model)
plot(varImp(ada.up.model), main = "Variable importance from Adaboost with Up Sample", col = 2, lwd = 2)
```

Confusion Matrix for adaboost on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(ada.up.model, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for adaboost on test set
```{r, echo=TRUE}
ada.pred <- predict(ada.up.model, model.test, type = "prob")[,2]
ada.prediction <- prediction(ada.pred,model.test$Manipulater)
ada.perf <- performance(ada.prediction, "tpr","fpr")

plot(ada.perf,main="ROC Curve for adaboost with upsample",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(ada.prediction, "auc")
```

###Boosting with adaboost (down sample)
The below code chunk sets some of the control parameters for adaboost
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='all', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE,
                           sampling = "down")#, p = 0.70) #in case method = #"LGOCV"
```

```{r}
search.grid <- expand.grid(mfinal = (1:10)*10, maxdepth = c(1,4),
                    coeflearn = c("Breiman", "Freund", "Zhu"))
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

ada.down.model <- train(model.train[,1:5], model.train[,6], 
                  method='AdaBoost.M1', 
                  trControl=objControl,
                  tuneGrid = search.grid,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for adaboost on train set
```{r, echo=TRUE}
#ada.down.model$finalModel #ada.down.model$results
print(ada.down.model)
confusionMatrix.train(ada.down.model)
plot(varImp(ada.down.model), main = "Variable importance from Adaboost with down sample", col = 2, lwd = 2)
```

Confusion Matrix for adaboost on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(ada.down.model, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for adaboost on test set
```{r, echo=TRUE}
ada.pred <- predict(ada.down.model, model.test, type = "prob")[,2]
ada.prediction <- prediction(ada.pred,model.test$Manipulater)
ada.perf <- performance(ada.prediction, "tpr","fpr")

plot(ada.perf,main="ROC Curve for adaboost with down sample",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(ada.prediction, "auc")
```

###Boosting with adaboost (SMOTE)
The below code chunk sets some of the control parameters for adaboost
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='all', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE,
                           sampling = "smote")#, p = 0.70) #in case method = #"LGOCV"
```

```{r}
search.grid <- expand.grid(mfinal = (1:10)*10, maxdepth = c(1,4),
                    coeflearn = c("Breiman", "Freund", "Zhu"))
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

ada.smote.model <- train(model.train[,1:5], model.train[,6], 
                  method='AdaBoost.M1', 
                  trControl=objControl,
                  tuneGrid = search.grid,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for adaboost on train set
```{r, echo=TRUE}
#ada.smote.model$finalModel #ada.smote.model$results
print(ada.smote.model)
confusionMatrix.train(ada.smote.model)
plot(varImp(ada.smote.model), main = "Variable importance from Adaboost with SMOTE", col = 2, lwd = 2)
```

Confusion Matrix for adaboost on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(ada.smote.model, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for adaboost on test set
```{r, echo=TRUE}
ada.pred <- predict(ada.smote.model, model.test, type = "prob")[,2]
ada.prediction <- prediction(ada.pred,model.test$Manipulater)
ada.perf <- performance(ada.prediction, "tpr","fpr")

plot(ada.perf,main="ROC Curve for adaboost with SMOTE",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(ada.prediction, "auc")
```

### Boosting with xgboost (normal)
The below code chunk sets some of the control parameters for adaboost
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='final', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE)
```

1. [Refer](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/) to know about the fine tuning parameters.
2. [This](http://topepo.github.io/caret/train-models-by-tag.html#Boosting) can also be referred to know about the parameter fine tuning.

```{r}
search.grid <- expand.grid(nrounds = (5:20)*10, max_depth = c(1:5)*2,
                    eta = c(0.01,0.03,0.09,0.3,0.5), 
                    gamma = c(0:3)/100,
                    colsample_bytree = c(2:5)/10,
                    min_child_weight = c(1:6))
                    #subsample = c(0.5:1))
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

xg.model <- train(model.train[,1:5], model.train[,6], 
                  method='xgbTree', 
                  trControl=objControl,
                  tuneGrid = search.grid,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for xgboost on train set
```{r, echo=TRUE}
#print(xg.model)
confusionMatrix.train(xg.model)

plot(varImp(xg.model), main = "Variable importance from xgboost", col = 2, lwd = 2)
```

Confusion Matrix for xgboost on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(xg.model, model.test[1:5], type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for xgboost on test set
```{r, echo=TRUE}
xg.pred <- predict(xg.model, model.test[1:5], type = "prob")[,2]
xg.prediction <- prediction(xg.pred,model.test$Manipulater)
xg.perf <- performance(xg.prediction, "tpr","fpr")

plot(xg.perf,main="ROC Curve for xgboost",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(xg.prediction, "auc")
```

### Boosting with xgboost (up sample)
The below code chunk sets some of the control parameters for adaboost
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='final', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE, sampling = "up")
```

```{r}
search.grid <- expand.grid(nrounds = (5:20)*10, max_depth = c(1:5)*2,
                    eta = c(0.01,0.03,0.09,0.3,0.5), 
                    gamma = c(0:3)/100,
                    colsample_bytree = c(2:5)/10,
                    min_child_weight = c(1:6))
                    #subsample = c(0.5:1))
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

xg.up.model <- train(model.train[,1:5], model.train[,6], 
                  method='xgbTree', 
                  trControl=objControl,
                  tuneGrid = search.grid,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for xgboost on train set
```{r, echo=TRUE}
#print(xg.up.model)
confusionMatrix.train(xg.up.model)

plot(varImp(xg.up.model), main = "Variable importance from xgboost with Up Sample", col = 2, lwd = 2)
```

Confusion Matrix for xgboost on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(xg.up.model, model.test[1:5], type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for xgboost on test set
```{r, echo=TRUE}
xg.pred <- predict(xg.up.model, model.test[1:5], type = "prob")[,2]
xg.prediction <- prediction(xg.pred,model.test$Manipulater)
xg.perf <- performance(xg.prediction, "tpr","fpr")

plot(xg.perf,main="ROC Curve for xgboost with Up Sample",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(xg.prediction, "auc")
```

### Boosting with xgboost (down sample)
The below code chunk sets some of the control parameters for adaboost
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='final', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE, sampling = "down")
```

```{r}
search.grid <- expand.grid(nrounds = (5:20)*10, max_depth = c(1:5)*2,
                    eta = c(0.01,0.03,0.09,0.3,0.5), 
                    gamma = c(0:3)/100,
                    colsample_bytree = c(2:5)/10,
                    min_child_weight = c(1:6))
                    #subsample = c(0.5:1))
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

xg.down.model <- train(model.train[,1:5], model.train[,6], 
                  method='xgbTree', 
                  trControl=objControl,
                  tuneGrid = search.grid,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for xgboost on train set
```{r, echo=TRUE}
#print(xg.down.model)
confusionMatrix.train(xg.down.model)

plot(varImp(xg.down.model), main = "Variable importance from xgboost with down sample", col = 2, lwd = 2)
```

Confusion Matrix for xgboost on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(xg.down.model, model.test[1:5], type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for xgboost on test set
```{r, echo=TRUE}
xg.pred <- predict(xg.down.model, model.test[1:5], type = "prob")[,2]
xg.prediction <- prediction(xg.pred,model.test$Manipulater)
xg.perf <- performance(xg.prediction, "tpr","fpr")

plot(xg.perf,main="ROC Curve for xgboost with down sample",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(xg.prediction, "auc")
```

### Boosting with xgboost (SMOTE)
The below code chunk sets some of the control parameters for adaboost
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='final', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE, sampling = "smote")
```

```{r}
search.grid <- expand.grid(nrounds = (5:20)*10, max_depth = c(1:5)*2,
                    eta = c(0.01,0.03,0.09,0.3,0.5), 
                    gamma = c(0:3)/100,
                    colsample_bytree = c(2:5)/10,
                    min_child_weight = c(1:6))
                    #subsample = c(0.5:1))
```

After setting the control paramters, the model is run
```{r, echo=TRUE}
set.seed(4121)

xg.smote.model <- train(model.train[,1:5], model.train[,6], 
                  method='xgbTree', 
                  trControl=objControl,
                  tuneGrid = search.grid,
                  metric = "ROC",
                  prox=TRUE,allowParallel=TRUE)
```

Confusion Matrix for xgboost on train set
```{r, echo=TRUE}
#print(xg.smote.model)
confusionMatrix.train(xg.smote.model)

plot(varImp(xg.smote.model), main = "Variable importance from xgboost with SMOTE", col = 2, lwd = 2)
```

Confusion Matrix for xgboost on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(xg.smote.model, model.test[1:5], type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for xgboost on test set
```{r, echo=TRUE}
xg.pred <- predict(xg.smote.model, model.test[1:5], type = "prob")[,2]
xg.prediction <- prediction(xg.pred,model.test$Manipulater)
xg.perf <- performance(xg.prediction, "tpr","fpr")

plot(xg.perf,main="ROC Curve for xgboost with SMOTE",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(xg.prediction, "auc")
```

## Neural Network

###Neural network implementation to find the manipulaters
The below code chunk sets some of the control parameters
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number = 5,
                           returnResamp='none', 
                           summaryFunction = twoClassSummary,
                           savePredictions = TRUE,
                           classProbs = TRUE)
```

Using search grid to fine tune the neural network. **Size** fine tunes number of hidden units to tune and **decay** fine tunes weight decay
```{r, echo=TRUE}
search.grid <- expand.grid(.decay = c(0.5, 0.1, 0.05), .size = c(2, 3, 4,5,6,7))
```

After setting the control paramters, the model is run. If we use **linout=TRUE** in **train()** the neural network builds a regression model. **linout=FALSE** will make **nnet** use a sigmodial function and all the predictions will be contrained between **[0,1]** 
```{r, echo=TRUE}
set.seed(4121)

nn.objModel <- train(model.train[,1:5], model.train[,6], 
                  method='nnet', 
                  trControl=objControl,  
                  metric = "ROC",
                  maxit = 1000,
                  tuneGrid = search.grid,
                  trace = FALSE,
                  linout = FALSE)
```

Confusion Matrix for Neural Network  on train set
```{r, echo=TRUE}
#nn.objModel$finalModel #nn.objModel$results
print(nn.objModel)
confusionMatrix.train(nn.objModel)
plot(varImp(nn.objModel), main = "Variable importance from Neural Network", col = 2, lwd = 2)
```

Confusion Matrix for Neural Network  on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(nn.objModel, model.test, type = "raw")
confusionMatrix(caretPredictedClass,model.test$Manipulater)
```

ROC plot for Neural Network on test set
```{r, echo=TRUE}
nn.pred <- predict(nn.objModel, model.test, type = "prob")[,2]
nn.prediction <- prediction(nn.pred,model.test$Manipulater)
nn.perf <- performance(nn.prediction, "tpr","fpr")

plot(nn.perf,main="ROC Curve for Neural Network",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(nn.prediction, "auc")
```

## Logistic Regression
The variables DSRI and GMI causes fitted probability to be numerically 0 or 1. Using less number of variables in the logistic regression.
```{r, echo=TRUE}
lg.model.data <- as.data.frame(filter.data[,c(#"DSRI",
                                          #"GMI",
                                          "AQI",
                                          "SGI",
                                          "DEPI",
                                          "SGAI",
                                          "ACCR",
                                          "LEVI",
                                          "Manipulater"
)])
lg.train.data <- as.data.frame(data.train[,c(#"DSRI",
                                          #"GMI",
                                          "AQI",
                                          "SGI",
                                          "DEPI",
                                          "SGAI",
                                          "ACCR",
                                          "LEVI",
                                          "Manipulater"
)])
lg.test.data <- as.data.frame(data.test[,c(#"DSRI",
                                          #"GMI",
                                          "AQI",
                                          "SGI",
                                          "DEPI",
                                          "SGAI",
                                          "ACCR",
                                          "LEVI",
                                          "Manipulater"
)])
```

The below code chunk sets some of the control parameters
```{r, echo=TRUE}
objControl <- trainControl(method='cv', number=5, 
                           returnResamp='none', 
                           summaryFunction = twoClassSummary, 
                           savePredictions = TRUE,
                           classProbs = TRUE)
```

After setting the control paramters, the model is run
```{r, include=FALSE}
set.seed(4121)
lg.objModel <- train(lg.train.data[,1:6], lg.train.data[,7], 
                     method='glmStepAIC', 
                     trControl=objControl,  
                     metric = "ROC")
```

Confusion Matrix for logistic regression on train set
```{r, echo=TRUE}
print(lg.objModel)
confusionMatrix.train(lg.objModel)
plot(varImp(lg.objModel), main = "Variable importance from Logistic Regression", col = 2, lwd = 2)
```

Confusion Matrix for logistic regression on test set
```{r, echo=TRUE}
caretPredictedClass <- predict(lg.objModel, lg.test.data, type = "raw")
confusionMatrix(caretPredictedClass,lg.test.data$Manipulater)
```

ROC plot for logistic regression
```{r, echo=TRUE}
lg.pred <- predict(lg.objModel, lg.test.data, type = "prob")[,2]
lg.prediction <- prediction(lg.pred,lg.test.data$Manipulater)
lg.perf <- performance(lg.prediction, "tpr","fpr")

plot(lg.perf,main="ROC Curve for Logistic Regression",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=3,col="black")

#AUC for the ROC plot
performance(lg.prediction, "auc")
```

End of document

***
